{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_grad_norm(model):\n",
    "    grad_all = 0.0\n",
    "    for p in model.parameters():\n",
    "        grad = 0.0\n",
    "        if p.grad is not None:\n",
    "            grad = (p.grad.cpu().data.numpy() ** 2).sum()\n",
    "        grad_all += grad\n",
    "    return grad_all ** 0.5\n",
    "\n",
    "# helper function for updating model based on loss of given x inputs and correct y outputs\n",
    "# returns loss from criterion\n",
    "def update_model(x_i, y_i, model, optimizer, criterion, no_unsqueeze=False, no_float=False, grad_norm=False, device=None):\n",
    "    if not no_float:\n",
    "        output = model(x_i.float())\n",
    "    else:\n",
    "        output = model(x_i)\n",
    "\n",
    "    if not no_unsqueeze:\n",
    "        y_i = y_i.unsqueeze(1)\n",
    "\n",
    "    if not no_float:\n",
    "        loss = criterion(output, y_i.float())\n",
    "    else:\n",
    "        loss = criterion(output, y_i)\n",
    "\n",
    "    if grad_norm:\n",
    "        loss = criterion(get_grad_norm(model), 0)\n",
    "\n",
    "\n",
    "    #print(loss)\n",
    "    out_loss = loss.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    return out_loss\n",
    "\n",
    "# Neural network with linear hidden layers\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_classes, hidden_size):\n",
    "        assert hidden_size >= 1\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        # input layer\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, hidden_size, bias=False)])\n",
    "        # hidden layers\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        # output layer\n",
    "        self.layers.append(nn.Linear(hidden_size, num_classes, bias=False))\n",
    "        #print(self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            out = layer(out)\n",
    "            #print(i, out.size())\n",
    "        return out\n",
    "\n",
    "    def num_parameters(self):\n",
    "        return self.input_size*self.hidden_size + self.num_layers*(self.hidden_size*self.hidden_size) + self.hidden_size*self.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "\n",
    "class FunctionDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = np.linspace(-5,5,2000)\n",
    "        x_term = 5*math.pi*self.x\n",
    "        self.y = np.array(list(map(math.sin,x_term)))/x_term\n",
    "        self.x_y = [(x,y) for x, y in zip(self.x, self.y)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _x = self.x_y[index][0]\n",
    "        _y = self.x_y[index][1]\n",
    "\n",
    "        return _x, _y\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _x = self.X[index]\n",
    "        _y = self.Y[index]\n",
    "        return _x, _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.num_parameters() 1980 4 22\n",
      "Epoch [1/10], Step [10/20], Loss: 0.0282\n",
      "Epoch [1/10], Step [20/20], Loss: 0.0171\n",
      "\n",
      "Epoch [2/10], Step [10/20], Loss: 0.0134\n",
      "Epoch [2/10], Step [20/20], Loss: 0.0066\n",
      "\n",
      "Epoch [3/10], Step [10/20], Loss: 0.0150\n",
      "Epoch [3/10], Step [20/20], Loss: 0.0146\n",
      "\n",
      "Epoch [4/10], Step [10/20], Loss: 0.0071\n",
      "Epoch [4/10], Step [20/20], Loss: 0.0176\n",
      "\n",
      "Epoch [5/10], Step [10/20], Loss: 0.0180\n",
      "Epoch [5/10], Step [20/20], Loss: 0.0145\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7131845542da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0my_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7854723d7a36>\u001b[0m in \u001b[0;36mupdate_model\u001b[0;34m(x_i, y_i, model, optimizer, criterion, no_unsqueeze, no_float, grad_norm, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2649\u001b[0m                 \u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m                 reduction=reduction)\n\u001b[0;32m-> 2651\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2652\u001b[0m         warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n\u001b[1;32m   2653\u001b[0m                       \u001b[0;34m\"This will likely lead to incorrect results due to broadcasting. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#\n",
    "# hyper parameters\n",
    "# \n",
    "input_size = 1\n",
    "output_size = 1\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "training_times = 1\n",
    "function_dataset = FunctionDataset()\n",
    "\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "xy_train = [x for x in function_dataset.x_y]\n",
    "#print(len(xy_train))\n",
    "training_set = TimeSeriesDataset([x[0] for x in xy_train], [y[1] for y in xy_train])\n",
    "\n",
    "#xy_test = [x for x in function_dataset.x_y[int(.9*len(function_dataset.x_y)):]]\n",
    "#print(len(xy_test))\n",
    "#testing_set = TimeSeriesDataset([x[0] for x in xy_test], [y[1] for y in xy_test])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#model\n",
    "num_layers = 4\n",
    "hidden_size = 22\n",
    "model = NeuralNet(input_size, num_layers=num_layers, hidden_size=hidden_size, num_classes=output_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"model.num_parameters()\",model.num_parameters(),num_layers,hidden_size)\n",
    "\n",
    "# Training\n",
    "n_total_steps = len(train_loader)\n",
    "mean_epoch_loss = []\n",
    "batch_loss = []\n",
    "grad_norm_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss_list = []\n",
    "    for i, (x_i, y_i) in enumerate(train_loader):\n",
    "        x_i = x_i.reshape(-1, input_size).to(device)\n",
    "        y_i = y_i.to(device)\n",
    "        if epoch >= num_epochs/2:\n",
    "            loss_list.append(update_model(x_i, y_i, model, optimizer, criterion, grad_norm=True,device=device))\n",
    "        else:\n",
    "            loss_list.append(update_model(x_i, y_i, model, optimizer, criterion))\n",
    "        grad_norm_list.append(get_grad_norm(model))\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss_list[-1]:.4f}')\n",
    "\n",
    "    batch_loss.extend(loss_list)\n",
    "    mean_epoch_loss.append(sum(loss_list)/len(loss_list))\n",
    "    print()\n",
    "\n",
    "fig, ax = plt.subplots(3,1)\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(14,13.5)\n",
    "ax[0].plot(range(len(batch_loss)), batch_loss,label='model loss',color='green')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_title('Model Loss')\n",
    "ax[0].set_xlabel('Iteration')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X = torch.from_numpy(np.array(training_set.X).astype(np.float32)).to(device)\n",
    "    X = X.reshape(len(X),1)\n",
    "    y_predicted = model(X)\n",
    "\n",
    "print(grad_norm_list)\n",
    "ax[1].plot(range(len(grad_norm_list)), grad_norm_list,label='model grad norm',color='green')\n",
    "ax[1].set_xlabel('Iteration')\n",
    "ax[1].set_ylabel('Grad Norm')\n",
    "\n",
    "ax[2].plot(function_dataset.x, function_dataset.y, color='black',label=r\"$\\frac{\\mathrm{sin}(5 \\pi x)}{5 \\pi x}$\")\n",
    "ax[2].xaxis.set_ticks_position('bottom')\n",
    "ax[2].yaxis.set_ticks_position('left')\n",
    "ax[2].set_xlim([0.01,1])\n",
    "ax[2].set_ylim([-.25,1])\n",
    "print(y_predicted.cpu())\n",
    "ax[2].plot(training_set.X, y_predicted.cpu(), color='green', label='model_2')\n",
    "ax[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
