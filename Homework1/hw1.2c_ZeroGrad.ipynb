{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim, flatten\n",
    "from torch.nn import Linear, Conv2d, MaxPool2d, BatchNorm2d, Module, Dropout, ReLU\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "from sklearn.decomposition import PCA \n",
    "from numpy.linalg import eig\n",
    "#from autograd_lib import autograd_lib\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0.01,1,300)\n",
    "x=x[:,None]\n",
    "y = np.sin(5 * 3.142 * x)/(5 * 3.142 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(1,30)\n",
    "        self.fc2 = nn.Linear(30,70)\n",
    "        self.fc3 = nn.Linear(70,1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24587066145027914"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Gradient Norm\n",
    "def grad_norm():\n",
    "    grad_all = 0.0\n",
    "    for p in model.parameters():\n",
    "        grad =0\n",
    "        if p.grad is not None:\n",
    "            grad = (p.grad.cpu().data.numpy() ** 2).sum()\n",
    "        grad_all+=grad\n",
    "    grad_norm = grad_all**0.5\n",
    "    return grad_norm\n",
    "\n",
    "grad_list = grad_norm()\n",
    "grad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfn(x):\n",
    "    loss = loss_fn(output, y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradloss(b):\n",
    "    loss = loss_fn(torch.tensor(grad_norm()), b)\n",
    "    #print(type(loss))\n",
    "    return loss\n",
    "l = gradloss(torch.tensor(0.0))\n",
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retloss(loss):\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs =1000\n",
    "model = Network()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "errorloss =[]\n",
    "costVector = []\n",
    "for i in range(10):\n",
    "    for xi,yi in zip(x,y):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xi)\n",
    "        loss = loss_fn(output, yi)\n",
    "        #print(loss.item())\n",
    "        loss.backward()\n",
    "        loss_norm = gradloss(torch.tensor(0.0))\n",
    "        #loss_norm = loss_fn(torch.tensor(grad_norm()),torch.tensor(0.0))\n",
    "        optimizer.step()\n",
    "        #print(type(loss_norm))\n",
    "        #print(loss_norm.item())\n",
    "\n",
    "        h = torch.autograd.functional.hessian(retloss, loss)\n",
    "        #h_eig = torch.symeig(h).eigenvalues \n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(2, 2)\n",
    "h = torch.autograd.functional.hessian(lossfn, inputs)\n",
    "e_value, e_vector = eig(h)\n",
    "e_vector[0][0]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = loss_fn(model)\n",
    "    errorloss.append(loss.item())\n",
    "    print(loss)\n",
    "    \n",
    "    h = torch.autograd.functional.hessian(lossfn, x, create_graph=True)\n",
    "w,v = eig(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0100],\n",
      "        [0.0133],\n",
      "        [0.0166],\n",
      "        [0.0199]])\n"
     ]
    }
   ],
   "source": [
    "print(x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0100]) tensor([0.9959])\n",
      "tensor([0.0133]) tensor([0.9927])\n",
      "tensor([0.0166]) tensor([0.9887])\n",
      "tensor([0.0199]) tensor([0.9837])\n"
     ]
    }
   ],
   "source": [
    "for xi,yi in zip(x[:4],y[:4]):\n",
    "    print(xi,yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
